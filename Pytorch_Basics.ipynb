{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1. Pytorch Basics\n",
    "\n",
    "Propose a PyTorch nn.Module that functions as a power equation: \n",
    "\n",
    "$y=x^n$\n",
    "\n",
    "Where x is a vector of positive values and parameter n should be learnable and constrained to values in the range [1, 3]. The outputs from the nn.Module forward method should always be positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "\n",
    "class LimitedPowah(nn.Module):\n",
    "    def __init__(self, eps = 1e-8, maxint = sys.maxsize):\n",
    "        super(LimitedPowah, self).__init__()\n",
    "        self.eps = eps\n",
    "        #As parameters should be constrained to range [1, 3], I can`t use torch.rand, as it works in the range [0,1)\n",
    "        self.learnable_param = nn.Parameter(1+2*(torch.randint(size=(1,), low = 0, high = maxint)/maxint))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.clamp(input=x, min = self.eps)\n",
    "        #Ensuring that outputs are always positive\n",
    "        out = torch.pow(x,self.learnable_param)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    #In case parameters should ALWAYS be constrained to range [1,3], here is code, which technically works\n",
    "    #I`m almost sure that I'm just overthinking, and it's just a bunch of cursed code\n",
    "    '''def clamp_parameters(self):\n",
    "        with torch.no_grad():\n",
    "            self.learnable_param.data.clamp_(1, 3)\n",
    "\n",
    "            \n",
    "    def parameters(self, recurse=True):\n",
    "        self.clamp_parameters()  \n",
    "        return super(LimitedPowah, self).parameters(recurse)\n",
    "    \n",
    "    def backward(self, loss):\n",
    "        loss.backward(retain_graph=True)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a Jupyter notebook to demonstrate the use of this nn.Module on a random valued batched vector (torch.tensor) with dimensions 8x16. In our case, 8 is a batch length and 16 is a length of the vector x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1]) Parameter containing:\n",
      "tensor([2.3111], requires_grad=True)\n",
      "tensor([[2.1405e+06, 1.3807e+06, 2.8691e+06, 1.3142e+06, 1.5979e+06, 6.8320e+06,\n",
      "         6.8564e+06, 1.7235e+05, 2.3583e+06, 1.5363e+05, 2.3992e+05, 3.5563e+06,\n",
      "         5.9958e+05, 3.6427e+06, 6.3846e+06, 7.0400e+06],\n",
      "        [1.4862e+05, 6.8089e+06, 3.3968e+05, 4.6003e+06, 1.6237e+06, 3.1180e+04,\n",
      "         7.7086e+06, 6.8642e+06, 4.2108e+04, 4.7643e+06, 7.1799e+06, 4.2327e+06,\n",
      "         9.3962e+05, 1.2421e+05, 3.5435e+06, 4.8426e+06],\n",
      "        [8.7937e+05, 3.3704e+05, 5.7563e+06, 1.2940e+04, 1.7501e+06, 2.5153e+06,\n",
      "         2.0497e+06, 3.9358e+05, 3.2814e+06, 1.1499e+05, 3.4409e+06, 5.1876e+05,\n",
      "         4.3719e+05, 2.9432e+05, 1.1694e+06, 7.9489e+05],\n",
      "        [1.4506e+06, 2.5858e+06, 9.0323e+04, 1.3978e+06, 1.5097e+06, 1.0409e+06,\n",
      "         4.0896e+06, 6.5904e+04, 5.1552e+05, 5.2908e+06, 3.1487e+06, 5.1563e+06,\n",
      "         5.0784e+06, 3.1559e+06, 6.1031e+05, 4.6518e+05],\n",
      "        [6.2641e+06, 2.9650e+06, 5.6354e+03, 2.8204e+06, 3.1826e+06, 3.2139e+05,\n",
      "         7.5125e+05, 7.1159e+04, 2.3782e+06, 8.2088e+06, 1.4271e+05, 7.1894e+05,\n",
      "         5.0540e+06, 5.0328e+06, 2.6605e+05, 7.4270e-01],\n",
      "        [6.8929e+06, 5.2492e+05, 1.4617e+06, 7.0773e+05, 8.4733e+05, 1.9196e+06,\n",
      "         3.6523e+06, 5.0857e+05, 2.9912e+05, 4.1871e+05, 6.1685e+06, 8.5517e+03,\n",
      "         1.2139e+06, 1.4304e+06, 7.0115e+05, 4.9614e+04],\n",
      "        [3.6465e+05, 6.7368e+05, 1.7256e+03, 6.1090e+05, 4.2875e+06, 1.0959e+05,\n",
      "         7.7954e+06, 1.7123e+03, 6.5186e+04, 7.3144e+03, 7.1740e+06, 5.6604e+05,\n",
      "         3.3152e+06, 2.1662e+06, 6.3069e+04, 6.0576e+06],\n",
      "        [4.6615e+06, 1.2710e+06, 3.3381e+06, 6.1285e+05, 6.4830e+06, 6.1361e+05,\n",
      "         4.4161e+06, 3.3724e+06, 3.1720e+04, 6.7638e+05, 2.3284e+06, 4.9270e+06,\n",
      "         5.6960e+05, 8.4645e+06, 2.7198e+06, 7.0157e+06]],\n",
      "       grad_fn=<PowBackward1>)\n"
     ]
    }
   ],
   "source": [
    "powah_module = LimitedPowah()\n",
    "for param in powah_module.parameters():\n",
    "    print(type(param), param.size(), param)\n",
    "\n",
    "#batched_vector = torch.zeros((8,16))\n",
    "#In case torch.rand returned 0\n",
    "batched_vector = torch.clamp(torch.rand((8,16)), min=1e-16)*1000\n",
    "\n",
    "y = powah_module(batched_vector)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cursed testings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1]) Parameter containing:\n",
      "tensor([1.3818], requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([1]) Parameter containing:\n",
      "tensor([3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "'''import torch.optim as optim\n",
    "powah_module_cursed = LimitedPowah()\n",
    "for param in powah_module_cursed.parameters():\n",
    "    print(type(param), param.size(), param)\n",
    "optimizer = optim.SGD(powah_module_cursed.parameters(), lr=1)\n",
    "\n",
    "input = torch.tensor(2.0)\n",
    "target = torch.tensor(1000.0)\n",
    "\n",
    "output = powah_module_cursed(input)\n",
    "\n",
    "loss = (output - target).pow(2)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "for param in powah_module_cursed.parameters():\n",
    "    print(type(param), param.size(), param)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
